#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Article Generator - Pipeline 4-Pass Principal
Seminary Blog System - Syst√®me de Blog Automatis√© SEO-First

Ce module orchestre le pipeline complet de g√©n√©ration d'articles :
Pass 1: G√©n√©ration Cr√©ative
Pass 2: Auto-Audit SEO
Pass 3: Auto-Am√©lioration
Pass 4: Finalisation & Int√©gration Seminary
"""

import os
import json
import logging
import requests
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from pathlib import Path
import re
from jinja2 import Template
import argparse

# Imports des modules Seminary
from context_manager import ContextManager
from seo_validator import SEOValidator
from image_handler import ImageHandler
from seminary_integrator import SeminaryIntegrator

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ArticleGenerator:
    """G√©n√©rateur d'articles complet avec pipeline 4-pass."""
    
    def __init__(self, chutes_api_key: str, unsplash_api_key: Optional[str] = None):
        """
        Initialise le g√©n√©rateur d'articles.
        
        Args:
            chutes_api_key: Cl√© API Chutes AI
            unsplash_api_key: Cl√© API Unsplash (optionnel)
        """
        self.chutes_api_key = chutes_api_key
        self.unsplash_api_key = unsplash_api_key
        
        # Initialiser les modules
        self.context_manager = ContextManager()
        self.seo_validator = SEOValidator()
        self.image_handler = ImageHandler(unsplash_api_key)
        self.seminary_integrator = SeminaryIntegrator()
        
        # Configuration de g√©n√©ration - Optimis√©e pour DeepSeek-R1
        self.generation_config = {
            'max_retries': 3,  # Moins de retries car ils sont longs
            'retry_delay': 20,  # D√©lai r√©duit
            'chutes_api_url': 'https://llm.chutes.ai/v1/chat/completions',  # URL officielle Chutes AI
            'chutes_model': 'deepseek-ai/DeepSeek-R1-0528',  # Mod√®le officiel Chutes AI
            'min_article_words': 600,  # Objectifs plus r√©alistes
            'max_article_words': 1500,
            'target_word_count': 900,  # Plus court pour √©viter les timeouts
            'seo_score_threshold': 70,  # Seuil plus permissif
            'max_improvement_attempts': 2,  # Moins d'am√©liorations
            'api_timeout': 180,  # 3 minutes pour DeepSeek-R1
            'max_tokens_per_call': 1500  # Limite pour √©viter les timeouts
        }
        
        # Templates de prompts
        self.prompts = {
            'creative_generation': '''
            √âcris DIRECTEMENT un article de blog de {target_words} mots sur les s√©minaires d'entreprise dans les Vosges.

            IMPORTANT: Ne montre pas ton processus de r√©flexion, donne directement l'article final.

            STRUCTURE:
            <h1>Titre principal</h1>
            <p>Introduction engageante</p>
            <h2>Section 1</h2>
            <p>Contenu...</p>
            <h2>Section 2</h2>
            <p>Contenu...</p>
            <h2>Conclusion</h2>
            <p>Appel √† l'action</p>

            MOTS-CL√âS: s√©minaire d'entreprise, Vosges, team building, formation, nature, montagne

            CONTEXTE EXISTANT: {context}
            ''',
            
            'seo_improvement': '''
            Am√©liore DIRECTEMENT cet article pour le SEO. Ne montre pas ton processus de r√©flexion.

            ARTICLE √Ä AM√âLIORER:
            {article_content}

            PROBL√àMES √Ä CORRIGER:
            {seo_issues}

            Renvoie UNIQUEMENT l'article HTML am√©lior√©:
            ''',
            
            'content_enrichment': '''
            Enrichis DIRECTEMENT cet article pour atteindre {target_words} mots. Ne montre pas ton processus de r√©flexion.

            ARTICLE √Ä ENRICHIR:
            {article_content}

            Ajoute: exemples concrets, b√©n√©fices entreprises, descriptions Vosges, conseils pratiques.

            Renvoie UNIQUEMENT l'article HTML enrichi:
            '''
        }
        
        # Charger le template d'article
        self.article_template = self._load_article_template()
    
    def _extract_final_content_from_deepseek(self, raw_content: str) -> str:
        """
        Extrait le contenu final du mod√®le DeepSeek-R1 qui expose son reasoning.
        Le mod√®le DeepSeek-R1 commence souvent par <think>...</think> puis donne la vraie r√©ponse.
        """
        import re
        
        # Cas 1: Contenu avec balises <think>
        if '<think>' in raw_content:
            # Chercher ce qui vient apr√®s </think>
            think_pattern = r'<think>.*?</think>\s*(.*)'
            match = re.search(think_pattern, raw_content, re.DOTALL)
            if match:
                final_content = match.group(1).strip()
                if final_content and len(final_content) > 100:  # Assurer un contenu substantiel
                    return final_content
        
        # Cas 2: Contenu qui commence directement par du reasoning
        lines = raw_content.split('\n')
        final_lines = []
        reasoning_ended = False
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # D√©tecter la fin du reasoning (phrases m√©ta sur le processus)
            if any(phrase in line.lower() for phrase in [
                'je vais', 'il faut', 'l\'utilisateur', 'je me concentre', 
                'il faudra', 'j\'√©viterai', 'hmm', 'probablement', 
                'semble avoir besoin', 'visiblement', 'la chute sur'
            ]):
                continue
                
            # Si c'est une phrase normale (pas du meta-reasoning)
            if (line.startswith('#') or  # Titre
                line.startswith('<') or   # HTML
                len(line.split()) > 5):   # Phrase substantielle
                reasoning_ended = True
                
            if reasoning_ended and line:
                final_lines.append(line)
        
        if final_lines and len('\n'.join(final_lines)) > 200:
            return '\n'.join(final_lines)
        
        # Cas 3: Fallback - prendre tout le contenu s'il semble valide
        if len(raw_content) > 300 and not raw_content.lower().startswith('hmm'):
            return raw_content
            
        # Cas 4: Contenu trop court ou invalide
        logger.warning("Contenu g√©n√©r√© insuffisant ou invalide")
        return raw_content
    
    def _load_article_template(self) -> Template:
        """Charge le template Jinja2 pour les articles."""
        template_path = Path('templates/article_template.html')
        
        try:
            with open(template_path, 'r', encoding='utf-8') as f:
                template_content = f.read()
            return Template(template_content)
        except FileNotFoundError:
            logger.error(f"Template non trouv√©: {template_path}")
            # Template minimal de fallback
            fallback_template = '''
            <!DOCTYPE html>
            <html lang="fr">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <title>{{ title }}</title>
                <meta name="description" content="{{ meta_description }}">
            </head>
            <body>
                {{ content | safe }}
            </body>
            </html>
            '''
            return Template(fallback_template)
    
    def call_chutes_api(self, prompt: str, max_tokens: int = 2000, temperature: float = 0.7) -> Optional[str]:
        """
        Appelle l'API Chutes AI avec le format officiel chat/completions.
        
        Args:
            prompt: Prompt √† envoyer
            max_tokens: Nombre maximum de tokens
            temperature: Cr√©ativit√© (0.0 √† 1.0)
            
        Returns:
            R√©ponse g√©n√©r√©e ou None si √©chec
        """
        headers = {
            'Authorization': f'Bearer {self.chutes_api_key}',
            'Content-Type': 'application/json'
        }
        
        # Format officiel Chutes AI chat/completions
        payload = {
            'model': self.generation_config['chutes_model'],
            'messages': [
                {
                    'role': 'user',
                    'content': prompt
                }
            ],
            'stream': False,  # Mode non-streaming pour simplifier
            'max_tokens': max_tokens,
            'temperature': temperature
        }
        
        for attempt in range(self.generation_config['max_retries']):
            try:
                logger.info(f"Appel Chutes AI (tentative {attempt + 1}/{self.generation_config['max_retries']})")
                logger.info(f"Mod√®le: {self.generation_config['chutes_model']}")
                
                response = requests.post(
                    self.generation_config['chutes_api_url'],
                    headers=headers,
                    json=payload,
                    timeout=self.generation_config['api_timeout']  # 3 minutes pour DeepSeek-R1
                )
                
                response.raise_for_status()
                result = response.json()
                
                # Format de r√©ponse OpenAI-compatible
                if 'choices' in result and len(result['choices']) > 0:
                    raw_text = result['choices'][0]['message']['content'].strip()
                    
                    if raw_text:
                        # Extraire le contenu final du mod√®le DeepSeek-R1
                        generated_text = self._extract_final_content_from_deepseek(raw_text)
                        logger.info(f"G√©n√©ration r√©ussie: {len(generated_text)} caract√®res (extrait de {len(raw_text)} caract√®res bruts)")
                        return generated_text
                    else:
                        logger.warning("Texte g√©n√©r√© vide")
                else:
                    logger.warning("Format de r√©ponse inattendu")
                    logger.debug(f"R√©ponse re√ßue: {result}")
                    
            except requests.exceptions.RequestException as e:
                logger.error(f"Erreur API (tentative {attempt + 1}): {e}")
                if attempt < self.generation_config['max_retries'] - 1:
                    logger.info(f"Attente de {self.generation_config['retry_delay']}s avant retry...")
                    time.sleep(self.generation_config['retry_delay'])
            except Exception as e:
                logger.error(f"Erreur inattendue: {e}")
                logger.debug(f"D√©tails de l'erreur: {str(e)}")
                break
        
        logger.error("√âchec de g√©n√©ration apr√®s tous les retries")
        return None
    
    def pass1_creative_generation(self, context: str) -> Optional[Dict]:
        """
        Pass 1: G√©n√©ration cr√©ative initiale.
        
        Args:
            context: Contexte des articles pr√©c√©dents
            
        Returns:
            Dictionnaire avec le contenu g√©n√©r√©
        """
        logger.info("=== PASS 1: G√âN√âRATION CR√âATIVE ===")
        
        prompt = self.prompts['creative_generation'].format(
            context=context,
            target_words=self.generation_config['target_word_count']
        )
        
        generated_content = self.call_chutes_api(
            prompt, 
            max_tokens=self.generation_config['max_tokens_per_call'],  # Limite pour √©viter les timeouts
            temperature=0.6  # Temp√©rature plus basse pour DeepSeek-R1
        )
        
        if not generated_content:
            return None
        
        # Nettoyer et structurer le contenu
        cleaned_content = self._clean_generated_content(generated_content)
        
        # Extraire les m√©tadonn√©es
        metadata = self._extract_metadata_from_content(cleaned_content)
        
        return {
            'content': cleaned_content,
            'metadata': metadata,
            'word_count': len(cleaned_content.split()),
            'generation_timestamp': datetime.now().isoformat()
        }
    
    def pass2_seo_audit(self, article_data: Dict) -> Dict:
        """
        Pass 2: Audit SEO automatique.
        
        Args:
            article_data: Donn√©es de l'article du Pass 1
            
        Returns:
            R√©sultats de l'audit SEO
        """
        logger.info("=== PASS 2: AUDIT SEO ===")
        
        # Cr√©er un HTML temporaire pour l'audit
        temp_html = self.article_template.render(
            title=article_data['metadata'].get('title', 'Article'),
            meta_description=article_data['metadata'].get('description', ''),
            content=article_data['content']
        )
        
        # Effectuer l'audit SEO
        audit_result = self.seo_validator.perform_full_audit(temp_html)
        
        logger.info(f"Score SEO: {audit_result['global_score']}/100")
        logger.info(f"Statut: {audit_result['status']}")
        
        if audit_result['major_issues']:
            logger.warning(f"Probl√®mes majeurs d√©tect√©s: {len(audit_result['major_issues'])}")
        
        return audit_result
    
    def pass3_auto_improvement(self, article_data: Dict, seo_audit: Dict) -> Optional[Dict]:
        """
        Pass 3: Auto-am√©lioration bas√©e sur l'audit SEO.
        
        Args:
            article_data: Donn√©es de l'article
            seo_audit: R√©sultats de l'audit SEO
            
        Returns:
            Article am√©lior√© ou None si √©chec
        """
        logger.info("=== PASS 3: AUTO-AM√âLIORATION ===")
        
        # V√©rifier si des am√©liorations sont n√©cessaires
        if seo_audit['global_score'] >= self.generation_config['seo_score_threshold']:
            logger.info("Score SEO suffisant, pas d'am√©lioration n√©cessaire")
            return article_data
        
        # Construire la liste des probl√®mes √† corriger
        issues_list = []
        issues_list.extend(seo_audit.get('major_issues', []))
        issues_list.extend(seo_audit.get('all_warnings', [])[:5])  # Top 5 warnings
        
        if not issues_list:
            logger.info("Aucun probl√®me sp√©cifique d√©tect√©")
            return article_data
        
        # Pr√©parer le prompt d'am√©lioration
        issues_text = '\n'.join(f"- {issue}" for issue in issues_list)
        
        for attempt in range(self.generation_config['max_improvement_attempts']):
            logger.info(f"Tentative d'am√©lioration {attempt + 1}/{self.generation_config['max_improvement_attempts']}")
            
            prompt = self.prompts['seo_improvement'].format(
                article_content=article_data['content'],
                seo_issues=issues_text
            )
            
            improved_content = self.call_chutes_api(
                prompt,
                max_tokens=3500,
                temperature=0.5  # Moins cr√©atif, plus focalis√©
            )
            
            if improved_content:
                # Nettoyer le contenu am√©lior√©
                cleaned_improved = self._clean_generated_content(improved_content)
                
                # V√©rifier l'am√©lioration
                improved_metadata = self._extract_metadata_from_content(cleaned_improved)
                
                # Test rapide du nouveau score
                temp_html = self.article_template.render(
                    title=improved_metadata.get('title', article_data['metadata']['title']),
                    meta_description=improved_metadata.get('description', ''),
                    content=cleaned_improved
                )
                
                quick_audit = self.seo_validator.perform_full_audit(temp_html)
                
                if quick_audit['global_score'] > seo_audit['global_score']:
                    logger.info(f"Am√©lioration r√©ussie: {seo_audit['global_score']} ‚Üí {quick_audit['global_score']}")
                    return {
                        'content': cleaned_improved,
                        'metadata': improved_metadata,
                        'word_count': len(cleaned_improved.split()),
                        'improvement_score': quick_audit['global_score'] - seo_audit['global_score']
                    }
                else:
                    logger.warning(f"Pas d'am√©lioration significative (tentative {attempt + 1})")
        
        logger.warning("√âchec de l'auto-am√©lioration, utilisation de la version originale")
        return article_data
    
    def pass4_seminary_integration(self, article_data: Dict) -> Dict:
        """
        Pass 4: Finalisation et int√©gration Seminary.
        
        Args:
            article_data: Donn√©es de l'article am√©lior√©
            
        Returns:
            Article final avec int√©grations Seminary
        """
        logger.info("=== PASS 4: INT√âGRATION SEMINARY ===")
        
        # G√©n√©rer le HTML complet
        final_html = self.article_template.render(
            title=article_data['metadata'].get('title', 'Article Seminary'),
            meta_description=article_data['metadata'].get('description', ''),
            content=article_data['content'],
            date=datetime.now().strftime('%Y-%m-%d'),
            author='Seminary Blog Bot'
        )
        
        # Int√©grer les liens Seminary
        seminary_result = self.seminary_integrator.process_article(
            final_html, 
            article_data['metadata'].get('title', '')
        )
        
        final_html = seminary_result['modified_html']
        
        logger.info(f"Liens Seminary ajout√©s: {seminary_result['links_added']}")
        
        # Ajouter une image si disponible
        if self.unsplash_api_key:
            try:
                image_suggestions = self.image_handler.suggest_images_for_article(
                    article_data['content'],
                    article_data['metadata'].get('title', '')
                )
                
                if image_suggestions:
                    best_image = image_suggestions[0]
                    image_path = self.image_handler.download_image(best_image)
                    
                    if image_path:
                        # Injecter l'image dans le HTML
                        final_html = self._inject_featured_image(final_html, image_path, best_image)
                        logger.info(f"Image ajout√©e: {image_path}")
                
            except Exception as e:
                logger.error(f"Erreur lors de l'ajout d'image: {e}")
        
        return {
            'final_html': final_html,
            'article_data': article_data,
            'seminary_integration': seminary_result,
            'generation_complete': True
        }
    
    def _clean_generated_content(self, content: str) -> str:
        """Nettoie le contenu g√©n√©r√© par l'IA."""
        # Supprimer les pr√©fixes ind√©sirables
        content = re.sub(r'^(Article|Voici|Voil√†):\s*', '', content, flags=re.IGNORECASE)
        
        # Nettoyer les balises HTML malform√©es
        content = re.sub(r'<([^>]+)>', lambda m: f'<{m.group(1).strip()}>', content)
        
        # Supprimer les doublons de balises
        content = re.sub(r'(<h[1-6][^>]*>)\s*\1', r'\1', content)
        
        # Assurer les balises fermantes
        if '<h1>' in content and '</h1>' not in content:
            content = content.replace('<h1>', '<h1>').replace('\n', '</h1>\n', 1)
        
        return content.strip()
    
    def _extract_metadata_from_content(self, content: str) -> Dict:
        """Extrait les m√©tadonn√©es du contenu g√©n√©r√©."""
        metadata = {}
        
        # Extraire le titre (H1)
        h1_match = re.search(r'<h1[^>]*>(.*?)</h1>', content, re.IGNORECASE | re.DOTALL)
        if h1_match:
            metadata['title'] = re.sub(r'<[^>]+>', '', h1_match.group(1)).strip()
        
        # G√©n√©rer une meta description bas√©e sur le premier paragraphe
        p_match = re.search(r'<p[^>]*>(.*?)</p>', content, re.IGNORECASE | re.DOTALL)
        if p_match:
            first_p = re.sub(r'<[^>]+>', '', p_match.group(1)).strip()
            # Limiter √† 160 caract√®res
            if len(first_p) > 160:
                metadata['description'] = first_p[:157] + '...'
            else:
                metadata['description'] = first_p
        
        return metadata
    
    def _inject_featured_image(self, html: str, image_path: str, image_info: Dict) -> str:
        """Injecte une image mise en avant dans l'article."""
        from bs4 import BeautifulSoup
        
        soup = BeautifulSoup(html, 'html.parser')
        
        # Cr√©er la balise image
        img_tag = soup.new_tag(
            'img',
            src=f"./images/{Path(image_path).name}",
            alt=image_info.get('suggested_alt_text', 'S√©minaire d\'entreprise'),
            title=image_info.get('suggested_title', 'Seminary'),
            style="width: 100%; max-width: 800px; height: auto; margin: 20px 0;"
        )
        
        # Trouver le premier paragraphe et ins√©rer l'image apr√®s
        content_div = soup.find('div', class_='article-content')
        if content_div:
            first_p = content_div.find('p')
            if first_p:
                first_p.insert_after(img_tag)
        
        return str(soup)
    
    def generate_filename(self, metadata: Dict) -> str:
        """G√©n√®re un nom de fichier pour l'article."""
        title = metadata.get('title', 'article')
        
        # Nettoyer le titre pour le nom de fichier
        clean_title = re.sub(r'[^\w\s-]', '', title.lower())
        clean_title = re.sub(r'\s+', '-', clean_title.strip())[:50]
        
        # Ajouter la date
        date_str = datetime.now().strftime('%Y-%m-%d')
        
        return f"{date_str}-{clean_title}.html"
    
    def save_article(self, final_result: Dict, filename: Optional[str] = None) -> str:
        """Sauvegarde l'article g√©n√©r√©."""
        if not filename:
            filename = self.generate_filename(final_result['article_data']['metadata'])
        
        # Assurer que le r√©pertoire articles existe
        articles_dir = Path('articles')
        articles_dir.mkdir(exist_ok=True)
        
        file_path = articles_dir / filename
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(final_result['final_html'])
            
            logger.info(f"Article sauvegard√©: {file_path}")
            return str(file_path)
            
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde: {e}")
            raise
    
    def generate_full_article(self) -> Optional[str]:
        """
        G√©n√®re un article complet via le pipeline 4-pass.
        
        Returns:
            Chemin du fichier g√©n√©r√© ou None si √©chec
        """
        start_time = time.time()
        logger.info("üöÄ D√âBUT DE G√âN√âRATION D'ARTICLE - PIPELINE 4-PASS")
        
        try:
            # Mettre √† jour le contexte
            context = self.context_manager.get_context_for_ai()
            
            # Pass 1: G√©n√©ration cr√©ative
            article_data = self.pass1_creative_generation(context)
            if not article_data:
                logger.error("√âchec du Pass 1 - G√©n√©ration cr√©ative")
                return None
            
            # Pass 2: Audit SEO
            seo_audit = self.pass2_seo_audit(article_data)
            
            # Pass 3: Auto-am√©lioration
            improved_article = self.pass3_auto_improvement(article_data, seo_audit)
            if not improved_article:
                logger.error("√âchec du Pass 3 - Auto-am√©lioration")
                return None
            
            # Pass 4: Int√©gration Seminary
            final_result = self.pass4_seminary_integration(improved_article)
            
            # Sauvegarder l'article
            file_path = self.save_article(final_result)
            
            # Mettre √† jour le contexte avec le nouvel article
            self.context_manager.update_context(self.chutes_api_key)
            
            # Statistiques finales
            duration = time.time() - start_time
            word_count = improved_article['word_count']
            
            logger.info(f"‚úÖ G√âN√âRATION TERMIN√âE")
            logger.info(f"üìÑ Fichier: {file_path}")
            logger.info(f"üìä Mots: {word_count}")
            logger.info(f"‚è±Ô∏è  Dur√©e: {duration:.1f}s")
            logger.info(f"üîó Liens Seminary: {final_result['seminary_integration']['links_added']}")
            
            return file_path
            
        except Exception as e:
            logger.error(f"Erreur critique dans le pipeline: {e}")
            return None


def main():
    """Point d'entr√©e principal pour l'ex√©cution standalone."""
    parser = argparse.ArgumentParser(description="Article Generator - Seminary Blog Pipeline")
    parser.add_argument('--chutes-api-key', required=True, help='Cl√© API Chutes AI')
    parser.add_argument('--unsplash-api-key', help='Cl√© API Unsplash (optionnel)')
    parser.add_argument('--update-context', action='store_true', help='Mettre √† jour le contexte uniquement')
    parser.add_argument('--dry-run', action='store_true', help='Test sans g√©n√©ration r√©elle')
    
    args = parser.parse_args()
    
    if args.update_context:
        # Mise √† jour du contexte uniquement
        context_manager = ContextManager()
        context_manager.update_context(args.chutes_api_key)
        print("‚úÖ Contexte mis √† jour")
        return
    
    if args.dry_run:
        print("üß™ MODE TEST - Pas de g√©n√©ration r√©elle")
        # Test de connexion API
        generator = ArticleGenerator(args.chutes_api_key, args.unsplash_api_key)
        test_response = generator.call_chutes_api("Test de connexion", max_tokens=10)
        if test_response:
            print("‚úÖ Connexion API r√©ussie")
        else:
            print("‚ùå √âchec de connexion API")
        return
    
    # G√©n√©ration normale
    generator = ArticleGenerator(args.chutes_api_key, args.unsplash_api_key)
    
    result_path = generator.generate_full_article()
    
    if result_path:
        print(f"‚úÖ Article g√©n√©r√© avec succ√®s: {result_path}")
    else:
        print("‚ùå √âchec de g√©n√©ration d'article")
        exit(1)


if __name__ == "__main__":
    main() 