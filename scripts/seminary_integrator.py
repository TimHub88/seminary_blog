#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Seminary Integrator - Int√©gration automatique des liens Seminary
Seminary Blog System - Syst√®me de Blog Automatis√© SEO-First

Ce module injecte automatiquement des liens pertinents vers les pages
Seminary dans les articles, en fonction du contexte et des mots-cl√©s.
"""

import re
import logging
import random
from typing import Dict, List, Tuple, Optional
from bs4 import BeautifulSoup, Tag

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SeminaryIntegrator:
    """Int√©grateur de liens Seminary pour les articles de blog."""
    
    def __init__(self):
        """Initialise l'int√©grateur avec les liens et r√®gles Seminary."""
        
        # Pages Seminary principales avec contextes d'usage
        self.seminary_pages = {
            'statistiques': {
                'url': 'https://goseminary.com/statistics',
                'title': 'Statistiques des s√©minaires Seminary',
                'description': 'Donn√©es et m√©triques sur les s√©minaires organis√©s',
                'keywords': ['statistiques', 'donn√©es', 'm√©triques', 'r√©sultats', 'chiffres', 'analyse'],
                'contexts': ['performance', 'efficacit√©', 'r√©sultats', '√©valuation', 'impact']
            },
            'reservations': {
                'url': 'https://goseminary.com/reservations',
                'title': 'R√©server votre s√©minaire Seminary',
                'description': 'Syst√®me de r√©servation en ligne pour vos √©v√©nements',
                'keywords': ['r√©servation', 'r√©server', 'booking', 'planifier', 'organiser', 'dates'],
                'contexts': ['planification', 'organisation', 'r√©servation', 'agenda', 'disponibilit√©s']
            },
            'prestataires': {
                'url': 'https://goseminary.com/providers',
                'title': 'Prestataires partenaires Seminary',
                'description': 'R√©seau de prestataires qualifi√©s pour vos s√©minaires',
                'keywords': ['prestataires', 'partenaires', 'fournisseurs', 'services', '√©quipe', 'experts'],
                'contexts': ['partenariat', 'collaboration', 'expertise', 'services', 'qualit√©']
            },
            'actualites': {
                'url': 'https://goseminary.com/news',
                'title': 'Actualit√©s Seminary',
                'description': 'Derni√®res nouvelles et mises √† jour Seminary',
                'keywords': ['actualit√©s', 'nouvelles', 'news', 'informations', 'mise √† jour'],
                'contexts': ['nouveaut√©s', '√©volutions', 'annonces', 'd√©veloppements']
            },
            'accueil': {
                'url': 'https://goseminary.com/',
                'title': 'Seminary - Organisateur de s√©minaires dans les Vosges',
                'description': 'Plateforme compl√®te pour organiser vos s√©minaires d\'entreprise',
                'keywords': ['seminary', 's√©minaires', 'vosges', 'entreprise', 'organisation'],
                'contexts': ['pr√©sentation', 'd√©couverte', 'services', 'offre globale']
            }
        }
        
        # Templates de liens contextuels
        self.link_templates = {
            'call_to_action': [
                "D√©couvrez nos {service} sur Seminary",
                "En savoir plus sur {service}",
                "Consultez {service} Seminary",
                "Acc√©dez √† {service}"
            ],
            'contextual': [
                "comme le montrent nos {service}",
                "selon nos {service}",
                "gr√¢ce √† nos {service}",
                "via notre syst√®me de {service}"
            ],
            'natural': [
                "nos {service}",
                "le syst√®me {service} de Seminary",
                "notre plateforme {service}",
                "les {service} Seminary"
            ]
        }
        
        # R√®gles d'int√©gration
        self.integration_rules = {
            'max_links_per_article': 4,
            'min_words_between_links': 150,
            'preferred_positions': ['middle', 'end'],  # d√©but, milieu, fin
            'avoid_link_clustering': True,
            'natural_integration_priority': True
        }
    
    def analyze_article_content(self, content: str, title: str) -> Dict:
        """
        Analyse le contenu de l'article pour identifier les opportunit√©s d'int√©gration.
        
        Args:
            content: Contenu textuel de l'article
            title: Titre de l'article
            
        Returns:
            Analyse avec mots-cl√©s et contextes identifi√©s
        """
        full_text = f"{title} {content}".lower()
        
        # Identifier les mots-cl√©s Seminary pr√©sents
        found_keywords = {}
        for page_key, page_info in self.seminary_pages.items():
            matches = []
            for keyword in page_info['keywords']:
                if keyword in full_text:
                    # Compter les occurrences et positions
                    positions = [m.start() for m in re.finditer(re.escape(keyword), full_text)]
                    matches.extend([(keyword, pos) for pos in positions])
            
            if matches:
                found_keywords[page_key] = {
                    'matches': matches,
                    'score': len(matches),
                    'relevance': self._calculate_relevance_score(matches, page_info, full_text)
                }
        
        # Analyser les contextes
        context_analysis = self._analyze_contexts(full_text)
        
        # Identifier les emplacements potentiels pour les liens
        potential_positions = self._find_link_positions(content)
        
        return {
            'found_keywords': found_keywords,
            'context_analysis': context_analysis,
            'potential_positions': potential_positions,
            'word_count': len(content.split()),
            'complexity_score': self._calculate_content_complexity(content)
        }
    
    def _calculate_relevance_score(self, matches: List[Tuple], page_info: Dict, text: str) -> float:
        """Calcule un score de pertinence pour une page Seminary."""
        score = len(matches) * 1.0  # Score de base
        
        # Bonus pour les contextes trouv√©s
        for context in page_info['contexts']:
            if context in text:
                score += 0.5
        
        # Bonus pour la diversit√© des mots-cl√©s
        unique_keywords = set([match[0] for match in matches])
        if len(unique_keywords) > 1:
            score += 1.0
        
        return score
    
    def _analyze_contexts(self, text: str) -> Dict:
        """Analyse les contextes dans le texte."""
        contexts = {
            'organizational': 0,
            'performance': 0,
            'planning': 0,
            'collaboration': 0,
            'innovation': 0
        }
        
        context_keywords = {
            'organizational': ['organisation', 'organiser', 'structure', 'gestion', 'management'],
            'performance': ['performance', 'r√©sultats', 'efficacit√©', 'productivit√©', 'am√©lioration'],
            'planning': ['planification', 'planning', 'agenda', 'programmation', 'calendrier'],
            'collaboration': ['collaboration', '√©quipe', 'teamwork', 'partenariat', 'ensemble'],
            'innovation': ['innovation', 'nouveaut√©', 'cr√©ativit√©', 'd√©veloppement', '√©volution']
        }
        
        for context, keywords in context_keywords.items():
            for keyword in keywords:
                contexts[context] += text.count(keyword)
        
        return contexts
    
    def _find_link_positions(self, content: str) -> List[Dict]:
        """Identifie les positions potentielles pour ins√©rer des liens."""
        sentences = re.split(r'[.!?]+', content)
        positions = []
        
        current_pos = 0
        for i, sentence in enumerate(sentences):
            sentence = sentence.strip()
            if not sentence:
                continue
            
            # Position dans le texte
            position_type = 'beginning' if i < len(sentences) * 0.3 else \
                           'middle' if i < len(sentences) * 0.7 else 'end'
            
            # Analyser le contenu de la phrase
            sentence_lower = sentence.lower()
            link_opportunities = []
            
            for page_key, page_info in self.seminary_pages.items():
                keyword_matches = sum(1 for kw in page_info['keywords'] if kw in sentence_lower)
                if keyword_matches > 0:
                    link_opportunities.append({
                        'page': page_key,
                        'keywords_count': keyword_matches,
                        'sentence': sentence[:100] + '...' if len(sentence) > 100 else sentence
                    })
            
            if link_opportunities:
                positions.append({
                    'sentence_index': i,
                    'position_type': position_type,
                    'character_position': current_pos,
                    'opportunities': link_opportunities,
                    'sentence_length': len(sentence.split())
                })
            
            current_pos += len(sentence) + 1
        
        return positions
    
    def _calculate_content_complexity(self, content: str) -> float:
        """Calcule un score de complexit√© du contenu."""
        words = content.split()
        sentences = re.split(r'[.!?]+', content)
        
        avg_word_length = sum(len(word) for word in words) / len(words) if words else 0
        avg_sentence_length = len(words) / len([s for s in sentences if s.strip()]) if sentences else 0
        
        complexity = (avg_word_length * 0.3) + (avg_sentence_length * 0.7)
        return min(complexity / 20, 1.0)  # Normaliser entre 0 et 1
    
    def generate_integration_plan(self, analysis: Dict) -> Dict:
        """
        G√©n√®re un plan d'int√©gration des liens Seminary.
        
        Args:
            analysis: R√©sultat de analyze_article_content
            
        Returns:
            Plan d√©taill√© pour l'int√©gration des liens
        """
        plan = {
            'recommended_links': [],
            'integration_strategy': 'natural',
            'total_links': 0,
            'confidence_score': 0.0
        }
        
        # Trier les pages par pertinence
        sorted_pages = sorted(
            analysis['found_keywords'].items(),
            key=lambda x: x[1]['relevance'],
            reverse=True
        )
        
        # S√©lectionner les liens √† int√©grer
        selected_positions = []
        for page_key, page_data in sorted_pages[:self.integration_rules['max_links_per_article']]:
            # Trouver la meilleure position pour ce lien
            best_position = self._find_best_position_for_page(
                page_key, analysis['potential_positions'], selected_positions
            )
            
            if best_position:
                link_info = self._create_link_info(page_key, best_position, page_data)
                plan['recommended_links'].append(link_info)
                selected_positions.append(best_position['character_position'])
        
        plan['total_links'] = len(plan['recommended_links'])
        plan['confidence_score'] = self._calculate_plan_confidence(plan, analysis)
        
        return plan
    
    def _find_best_position_for_page(self, page_key: str, positions: List[Dict], 
                                   used_positions: List[int]) -> Optional[Dict]:
        """Trouve la meilleure position pour un lien vers une page Seminary."""
        page_info = self.seminary_pages[page_key]
        
        # Filtrer les positions qui correspondent √† cette page
        relevant_positions = []
        for pos in positions:
            for opp in pos['opportunities']:
                if opp['page'] == page_key:
                    # V√©rifier la distance avec les liens existants
                    min_distance = float('inf')
                    for used_pos in used_positions:
                        distance = abs(pos['character_position'] - used_pos)
                        min_distance = min(min_distance, distance)
                    
                    if min_distance > self.integration_rules['min_words_between_links']:
                        relevant_positions.append({
                            **pos,
                            'distance_score': min_distance,
                            'keyword_score': opp['keywords_count']
                        })
        
        if not relevant_positions:
            return None
        
        # Trier par score combin√©
        relevant_positions.sort(
            key=lambda x: (x['keyword_score'] * 2 + x['distance_score'] / 100),
            reverse=True
        )
        
        return relevant_positions[0]
    
    def _create_link_info(self, page_key: str, position: Dict, page_data: Dict) -> Dict:
        """Cr√©e les informations d√©taill√©es pour un lien."""
        page_info = self.seminary_pages[page_key]
        
        # Choisir le type de lien bas√© sur la position
        link_type = 'natural' if position['position_type'] == 'middle' else \
                   'contextual' if position['position_type'] == 'beginning' else \
                   'call_to_action'
        
        # G√©n√©rer le texte du lien
        link_text = self._generate_link_text(page_key, link_type, page_data)
        
        return {
            'page_key': page_key,
            'url': page_info['url'],
            'link_text': link_text,
            'title': page_info['title'],
            'position': position,
            'link_type': link_type,
            'confidence': page_data['relevance'] / 5.0  # Normaliser
        }
    
    def _generate_link_text(self, page_key: str, link_type: str, page_data: Dict) -> str:
        """G√©n√®re un texte de lien naturel et optimis√©."""
        page_info = self.seminary_pages[page_key]
        
        # S√©lectionner un template appropri√©
        templates = self.link_templates.get(link_type, self.link_templates['natural'])
        template = random.choice(templates)
        
        # Adapter le service selon la page
        service_names = {
            'statistiques': 'statistiques d√©taill√©es',
            'reservations': 'syst√®me de r√©servation',
            'prestataires': 'r√©seau de prestataires',
            'actualites': 'derni√®res actualit√©s',
            'accueil': 'plateforme Seminary'
        }
        
        service_name = service_names.get(page_key, page_info['title'])
        
        # G√©n√©rer le texte final
        if '{service}' in template:
            link_text = template.format(service=service_name)
        else:
            link_text = template
        
        return link_text
    
    def _calculate_plan_confidence(self, plan: Dict, analysis: Dict) -> float:
        """Calcule un score de confiance pour le plan d'int√©gration."""
        if not plan['recommended_links']:
            return 0.0
        
        # Score bas√© sur la pertinence moyenne des liens
        avg_confidence = sum(link['confidence'] for link in plan['recommended_links']) / len(plan['recommended_links'])
        
        # Bonus pour la diversit√© des pages li√©es
        unique_pages = set(link['page_key'] for link in plan['recommended_links'])
        diversity_bonus = len(unique_pages) / len(plan['recommended_links'])
        
        # Malus si trop de liens ou trop peu
        optimal_links = min(3, max(1, analysis['word_count'] // 300))
        link_count_score = 1.0 - abs(len(plan['recommended_links']) - optimal_links) * 0.2
        
        confidence = (avg_confidence * 0.6) + (diversity_bonus * 0.2) + (link_count_score * 0.2)
        return min(confidence, 1.0)
    
    def integrate_links_into_html(self, html_content: str, integration_plan: Dict) -> str:
        """
        Int√®gre les liens Seminary dans le contenu HTML.
        
        Args:
            html_content: Contenu HTML de l'article
            integration_plan: Plan d'int√©gration g√©n√©r√©
            
        Returns:
            HTML modifi√© avec les liens int√©gr√©s
        """
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # Trouver le contenu principal de l'article
            content_div = soup.find('div', class_='article-content')
            if not content_div:
                logger.warning("Div article-content non trouv√©e, utilisation du body")
                content_div = soup.find('body')
            
            if not content_div:
                logger.error("Impossible de localiser le contenu √† modifier")
                return html_content
            
            # Extraire le texte pour rep√©rage des positions
            text_content = content_div.get_text()
            
            # Int√©grer chaque lien
            links_added = 0
            for link_info in integration_plan['recommended_links']:
                if self._integrate_single_link(content_div, link_info, text_content):
                    links_added += 1
            
            logger.info(f"Liens Seminary int√©gr√©s: {links_added}/{len(integration_plan['recommended_links'])}")
            return str(soup)
            
        except Exception as e:
            logger.error(f"Erreur lors de l'int√©gration des liens: {e}")
            return html_content
    
    def _integrate_single_link(self, content_div: Tag, link_info: Dict, text_content: str) -> bool:
        """Int√®gre un seul lien dans la section de contenu."""
        try:
            # Acc√®s s√©curis√© aux donn√©es de position
            position_data = link_info.get('position', {})
            
            # Essayer diff√©rentes cl√©s possibles pour obtenir la phrase cible
            target_sentence = None
            if isinstance(position_data, dict):
                # Essayer les cl√©s possibles
                if 'sentence' in position_data:
                    target_sentence = position_data['sentence']
                elif 'opportunities' in position_data and position_data['opportunities']:
                    target_sentence = position_data['opportunities'][0].get('sentence', '')
                elif 'text' in position_data:
                    target_sentence = position_data['text']
            
            if not target_sentence:
                # Fallback: utiliser le mot-cl√© cible pour trouver une phrase
                target_keyword = link_info.get('target_keyword', '')
                if target_keyword:
                    # Chercher une phrase contenant le mot-cl√©
                    for p_tag in content_div.find_all('p'):
                        if target_keyword.lower() in p_tag.get_text().lower():
                            target_sentence = p_tag.get_text()[:100]  # Premiers 100 caract√®res
                            break
            
            if not target_sentence:
                logger.warning(f"Impossible de trouver une phrase cible pour le lien: {link_info.get('page_key', 'unknown')}")
                return False
            
            # Chercher le paragraphe correspondant
            paragraphs = content_div.find_all('p')
            for p_tag in paragraphs:
                p_text = p_tag.get_text()
                if target_sentence[:50] in p_text:  # Match partiel pour robustesse
                    # Cr√©er le lien
                    link_tag = content_div.new_tag(
                        'a',
                        href=link_info.get('url', '#'),
                        title=link_info.get('title', ''),
                        target='_blank',
                        rel='noopener',
                        **{'class': 'seminary-link'}
                    )
                    link_tag.string = link_info.get('link_text', link_info.get('target_keyword', 'Seminary'))
                    
                    # Remplacer le terme
                    if self._replace_term_with_link(p_tag, link_info, link_tag):
                        logger.info(f"Lien int√©gr√© pour: {link_info.get('page_key', 'unknown')}")
                        return True
                    break
            
            logger.warning(f"Impossible de trouver une position pour le lien: {link_info.get('page_key', 'unknown')}")
            return False
            
        except Exception as e:
            logger.error(f"Erreur lors de l'int√©gration d'un lien: {e}")
            return False

    def _replace_term_with_link(self, p_tag: Tag, link_info: Dict, link_tag: Tag) -> bool:
        """Remplace un terme par un lien dans un paragraphe."""
        
        best_term_to_replace = link_info.get('target_keyword')
        if not best_term_to_replace:
            logger.warning("Aucun mot-cl√© cible pour le remplacement.")
            return False

        original_text = p_tag.get_text()
        pattern = re.compile(r'\b' + re.escape(best_term_to_replace) + r'\b', re.IGNORECASE)
        match = pattern.search(original_text)
        
        if match:
            start, end = match.span()
            before_text = original_text[:start]
            after_text = original_text[end:]
            
            p_tag.clear()
            p_tag.append(before_text)
            p_tag.append(link_tag)
            p_tag.append(after_text)
            return True
        
        return False
    
    def process_article(self, html_content: str, article_title: str = "") -> Dict:
        """
        Traite un article complet pour l'int√©gration Seminary.
        
        Args:
            html_content: Contenu HTML de l'article
            article_title: Titre de l'article (optionnel)
            
        Returns:
            R√©sultat du traitement avec HTML modifi√© et statistiques
        """
        # Extraire le contenu textuel pour analyse
        soup = BeautifulSoup(html_content, 'html.parser')
        text_content = soup.get_text()
        
        if not article_title:
            title_tag = soup.find('h1')
            article_title = title_tag.get_text() if title_tag else ""
        
        # Analyser le contenu
        analysis = self.analyze_article_content(text_content, article_title)
        
        # G√©n√©rer le plan d'int√©gration
        integration_plan = self.generate_integration_plan(analysis)
        
        # Int√©grer les liens si le plan est viable
        if integration_plan['confidence_score'] > 0.3:  # Seuil de confiance minimum
            modified_html = self.integrate_links_into_html(html_content, integration_plan)
        else:
            modified_html = html_content
            logger.info("Plan d'int√©gration rejet√© (confiance trop faible)")
        
        return {
            'modified_html': modified_html,
            'analysis': analysis,
            'integration_plan': integration_plan,
            'links_added': len(integration_plan['recommended_links']) if integration_plan['confidence_score'] > 0.3 else 0,
            'confidence_score': integration_plan['confidence_score']
        }


def main():
    """Point d'entr√©e pour les tests CLI."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Seminary Integrator - Seminary Blog")
    parser.add_argument('file', help='Fichier HTML √† traiter')
    parser.add_argument('--analyze-only', action='store_true', help='Analyser sans modifier')
    parser.add_argument('--output', help='Fichier de sortie (d√©faut: remplace l\'original)')
    
    args = parser.parse_args()
    
    try:
        with open(args.file, 'r', encoding='utf-8') as f:
            html_content = f.read()
        
        integrator = SeminaryIntegrator()
        result = integrator.process_article(html_content)
        
        print(f"=== INT√âGRATION SEMINARY - {args.file} ===")
        print(f"Score de confiance: {result['confidence_score']:.2f}")
        print(f"Liens ajout√©s: {result['links_added']}")
        
        if result['integration_plan']['recommended_links']:
            print("\nüìé LIENS RECOMMAND√âS:")
            for link in result['integration_plan']['recommended_links']:
                print(f"  - {link['link_text']} ‚Üí {link['page_key']}")
        
        if not args.analyze_only and result['links_added'] > 0:
            output_file = args.output or args.file
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(result['modified_html'])
            print(f"\n‚úÖ Fichier modifi√© sauvegard√©: {output_file}")
        
    except FileNotFoundError:
        print(f"Fichier non trouv√©: {args.file}")
    except Exception as e:
        print(f"Erreur: {e}")


if __name__ == "__main__":
    main() 